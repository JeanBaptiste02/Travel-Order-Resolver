{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E004] Can't set up pipeline component: a factory for 'language_detector' already exists. Existing factory: <function install_language_detector.<locals>.language_detector at 0x00000221669471A0>. New factory: <function install_language_detector.<locals>.language_detector at 0x0000022166927E20>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguageDetector est déjà présent dans la pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Installer et configurer le détecteur de langue\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m install_language_detector()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Fonction pour extraire les entités de départ et destination du texte\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_locations\u001b[39m(text, lang_model, itinerary_model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36minstall_language_detector\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_detector\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m nlp_fr\u001b[38;5;241m.\u001b[39mpipe_names:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Si elle n'existe pas, définir la factory\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(Language\u001b[38;5;241m.\u001b[39mfactories, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_detector\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;129m@Language\u001b[39m\u001b[38;5;241m.\u001b[39mfactory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_detector\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlanguage_detector\u001b[39m(nlp, name):\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m LanguageDetector()\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Ajouter le détecteur de langue à la pipeline\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\language.py:518\u001b[0m, in \u001b[0;36mLanguage.factory.<locals>.add_factory\u001b[1;34m(factory_func)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_same_func(factory_func, existing_func):\n\u001b[0;32m    515\u001b[0m         err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE004\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    516\u001b[0m             name\u001b[38;5;241m=\u001b[39mname, func\u001b[38;5;241m=\u001b[39mexisting_func, new_func\u001b[38;5;241m=\u001b[39mfactory_func\n\u001b[0;32m    517\u001b[0m         )\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    520\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mget_arg_names(factory_func)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m arg_names \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m arg_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E004] Can't set up pipeline component: a factory for 'language_detector' already exists. Existing factory: <function install_language_detector.<locals>.language_detector at 0x00000221669471A0>. New factory: <function install_language_detector.<locals>.language_detector at 0x0000022166927E20>"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm  # Affichage d'une barre de progression\n",
    "import difflib  # Recherche de similarité entre deux chaînes de caractères\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "# Charger le modèle entraîné pour l'itinéraire\n",
    "nlp_itinerary = spacy.load(\"../../models/saved_models/model-best/\")\n",
    "# Charger le modèle pré-entraîné en français\n",
    "nlp_fr = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction pour installer et configurer le détecteur de langue\n",
    "# -------------------------------------------------------------------------------\n",
    "def install_language_detector():\n",
    "    # Vérifier si la factory 'language_detector' existe déjà\n",
    "    if 'language_detector' not in nlp_fr.pipe_names:\n",
    "        # Si elle n'existe pas, définir la factory\n",
    "        if not hasattr(Language.factories, 'language_detector'):\n",
    "            @Language.factory('language_detector')\n",
    "            def language_detector(nlp, name):\n",
    "                return LanguageDetector()\n",
    "        # Ajouter le détecteur de langue à la pipeline\n",
    "        nlp_fr.add_pipe('language_detector', last=True)\n",
    "        print(\"LanguageDetector ajouté à la pipeline\")\n",
    "    else:\n",
    "        print(\"LanguageDetector est déjà présent dans la pipeline\")\n",
    "\n",
    "\n",
    "# Installer et configurer le détecteur de langue\n",
    "install_language_detector()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction pour extraire les entités de départ et destination du texte\n",
    "# -------------------------------------------------------------------------------\n",
    "def extract_locations(text, lang_model, itinerary_model, verbose=False):\n",
    "    doc_lang = lang_model(text)\n",
    "    doc_itinerary = itinerary_model(text)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Entités détectées avec le modèle linguistique :\")\n",
    "        spacy.displacy.render(doc_lang, style='ent', jupyter=True)\n",
    "        print(\"Entités détectées avec le modèle itinéraire :\")\n",
    "        spacy.displacy.render(doc_itinerary, style='ent', jupyter=True)\n",
    "\n",
    "    departure, destination = None, None\n",
    "\n",
    "    # Vérifier si le texte est bien en français\n",
    "    if doc_lang._.language['language'] != 'fr':\n",
    "        return \"NON_FRANÇAIS\"\n",
    "\n",
    "    # Parcourir les entités détectées par le modèle d'itinéraire\n",
    "    for ent in doc_itinerary.ents:\n",
    "        if ent.label_ == \"DEPARTURE\":\n",
    "            departure = ent.text\n",
    "        elif ent.label_ == \"DESTINATION\":\n",
    "            destination = ent.text\n",
    "\n",
    "    if not departure or not destination:\n",
    "        return \"PAS_DE_TRAJET\"\n",
    "    \n",
    "    return {\"départ\": departure, \"destination\": destination}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction pour traiter un fichier et extraire les informations de départ et destination\n",
    "# -------------------------------------------------------------------------------\n",
    "def process_file(filepath, lang_model, itinerary_model, verbose=False):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    result_trips = []\n",
    "    for line in lines:\n",
    "        elements = line.strip().split(',', 1)\n",
    "        id_ = elements[0] if elements[0].isdigit() else 0\n",
    "        text = elements[1] if len(elements) > 1 else elements[0]\n",
    "\n",
    "        trips = extract_locations(text, lang_model, itinerary_model, verbose)\n",
    "        if trips == \"NON_FRANÇAIS\" or trips == \"PAS_DE_TRAJET\":\n",
    "            result_trips.append(f\"{id_},{trips}\")\n",
    "        else:\n",
    "            result_trips.append(f\"{id_},{trips['départ']},{trips['destination']}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Trajets extraits :\")\n",
    "        print(result_trips)\n",
    "\n",
    "    return result_trips\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction de comparaison des résultats extraits avec les résultats attendus\n",
    "# -------------------------------------------------------------------------------\n",
    "def compare_trips(extracted, expected):\n",
    "    errors = 0\n",
    "    for i in range(len(extracted)):\n",
    "        if extracted[i] != expected[i]:\n",
    "            errors += 1\n",
    "            print(f\"Erreur ligne {i+1} :\")\n",
    "            print(f\"Extrait : {extracted[i]}\")\n",
    "            print(f\"Attendu : {expected[i]}\")\n",
    "\n",
    "    # Calcul du taux de réussite\n",
    "    success_rate = round((len(extracted) - errors) / len(extracted) * 100, 2)\n",
    "    print(f\"\\nTaux de réussite : {success_rate}% ({errors} erreurs sur {len(extracted)} lignes).\\n\")\n",
    "\n",
    "    # Affichage d'un graphique circulaire pour visualiser le taux de réussite\n",
    "    labels = 'Réussites', 'Erreurs'\n",
    "    sizes = [len(extracted) - errors, errors]\n",
    "    colors = ['green', 'red']\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "    # Comparaison des résultats sous forme de tableau avec pandas\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [item.split(',')[0] for item in extracted],\n",
    "        'Départ Attendu': [item.split(',')[1] if len(item.split(',')) > 1 else '' for item in expected],\n",
    "        'Départ Prévu': [item.split(',')[1] if len(item.split(',')) > 1 else '' for item in extracted],\n",
    "        'Destination Attendue': [item.split(',')[2] if len(item.split(',')) > 2 else '' for item in expected],\n",
    "        'Destination Prévue': [item.split(',')[2] if len(item.split(',')) > 2 else '' for item in extracted],\n",
    "    })\n",
    "\n",
    "    print(\"\\nComparaison des résultats :\\n\", df)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction de correction des villes en utilisant la liste de villes\n",
    "# -------------------------------------------------------------------------------\n",
    "def correct_cities(trips, city_list, verbose=False):\n",
    "    corrected_trips = []\n",
    "    for trip in trips:\n",
    "        parts = trip.upper().replace('É', 'E').replace('-', ' ').split(',')\n",
    "        corrected_trip = ','.join([difflib.get_close_matches(item, city_list, n=1, cutoff=0.8)[0] if difflib.get_close_matches(item, city_list, n=1, cutoff=0.8) else item for item in parts])\n",
    "        corrected_trips.append(corrected_trip)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Avant : {trip}\")\n",
    "            print(f\"Après correction : {corrected_trip}\")\n",
    "\n",
    "    return corrected_trips\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Fonction principale pour l'analyse d'un fichier et la comparaison avec les résultats attendus\n",
    "# -------------------------------------------------------------------------------\n",
    "def analyze_nlp(file_path_input, file_path_output):\n",
    "    with open(file_path_input, 'r') as file:\n",
    "        print(f\"Lecture du fichier d'entrée :\\n{file.read()}\")\n",
    "\n",
    "    with open(file_path_output, 'r', encoding='utf-8') as file:\n",
    "        reference_trips = [line.strip().rstrip(',') for line in file.readlines()]\n",
    "\n",
    "    print(\"\\nANALYSE BRUTE (SANS PRÉTRAITEMENT)\\n\")\n",
    "    raw_output_trips = process_file(file_path_input, nlp_fr, nlp_itinerary, True)\n",
    "    compare_trips(raw_output_trips, reference_trips)\n",
    "\n",
    "    print(\"\\nANALYSE APRÈS PRÉTRAITEMENT\\n\")\n",
    "    processed_output_trips = correct_cities(raw_output_trips, '../utils/extra_datas/urban_geodata_basic_v1.0.txt')\n",
    "    processed_reference_trips = correct_cities(reference_trips, '../utils/extra_datas/urban_geodata_basic_v1.0.txt')\n",
    "    compare_trips(processed_output_trips, processed_reference_trips)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Exécution de l'analyse avec les fichiers d'entrée et de sortie\n",
    "# -------------------------------------------------------------------------------\n",
    "file_path_input = '../utils/test_data/nlp_input_data.txt'\n",
    "file_path_output = '../utils/test_data/nlp_output_data.txt'\n",
    "\n",
    "analyze_nlp(file_path_input, file_path_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
