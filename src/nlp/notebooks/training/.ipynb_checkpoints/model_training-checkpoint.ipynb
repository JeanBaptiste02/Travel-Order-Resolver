{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803cc27b-c2ff-47af-a9a4-920796c55fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.util import Config\n",
    "from spacy.training import Corpus\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558bd341-5e63-4771-937e-2afff077d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy model charged success\n"
     ]
    }
   ],
   "source": [
    "nlp_fr = spacy.load(\"fr_core_news_md\")\n",
    "print(\"spacy model charged success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dcdac46-48c5-4008-9840-8988bb38a377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Je voudrais aller de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ermont\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " à \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sannois\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". ...</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texte_simple = '''Je voudrais aller de Ermont à Sannois. ...'''\n",
    "doc = nlp_fr(texte_simple)\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48c0798-833d-42c2-9f2d-5f32ac71928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ficheir csv chargé\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# charger le fichier CSV\n",
    "df = pd.read_csv('../../dataset/raw/initial_training_data.csv')\n",
    "print(\"\\nFicheir csv chargé\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e13ef5-61e9-4e0a-a111-0b8f9cbec4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  entity_start  \\\n",
      "0  Quels sites touristiques visiter en allant de ...            46   \n",
      "1  Quels sites touristiques visiter en allant de ...            54   \n",
      "2  Combien de temps faut-il pour aller de PARIS à...            39   \n",
      "3  Combien de temps faut-il pour aller de PARIS à...            47   \n",
      "4  Quels sont les moyens de transport les plus éc...            70   \n",
      "\n",
      "   entity_end  entity_type  \n",
      "0          51    DEPARTURE  \n",
      "1          63  DESTINATION  \n",
      "2          44    DEPARTURE  \n",
      "3          51  DESTINATION  \n",
      "4          75    DEPARTURE  \n"
     ]
    }
   ],
   "source": [
    "# premieres lignes du dataset pour verifier le chargement\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602648ec-4a39-4056-a0a3-0dd683e06b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conteneur crée\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# on cree un conteneur pour stocker les documents au format spaCy\n",
    "db = DocBin()\n",
    "print(\"\\nconteneur crée\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34d39a24-b214-4d8b-a59c-82a4dce503a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on melange les  pour éviter tout biais dans l'apprentissage\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "127afe39-6ecf-4206-8434-9c9fd48ab46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499000/499000 [05:41<00:00, 1460.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# on convertit les donnees au format spaCy\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    text = row['sentence']\n",
    "    doc = nlp_fr.make_doc(text)  # on cree un document spaCy a partir du texte\n",
    "    ents = []\n",
    "    \n",
    "    # recuperer les infos des labels\n",
    "    start = row['entity_start']\n",
    "    end = row['entity_end']\n",
    "    label = row['entity_type']\n",
    "    \n",
    "    # creation d'une entite spaCy à partir des coordonnees de debut et de fin\n",
    "    span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "    if span is not None:\n",
    "        ents.append(span)\n",
    "    \n",
    "    doc.ents = ents  # assigner les entites au document\n",
    "    db.add(doc)  # ajouter le document au DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66afaf0e-3649-4f53-a995-1b5bf82b5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistre les donnes converties au format spaCy\n",
    "db.to_disk(\"../../dataset/processed/training_data.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "297d7b98-e2db-4674-84bf-efac63b69c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout du composant NER au modele actuel\n",
    "ner = nlp_fr.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f9bfe3c-b3e1-4576-9b36-93a17b380c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajoute de nouveaux labels d'entites a partir des donnes\n",
    "for _, row in df.iterrows():\n",
    "    ner.add_label(row['entity_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e0660a6-3abc-468c-9719-70f981e0ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les nouvelles étiquettes NER ont été ajoutées au modèle.\n"
     ]
    }
   ],
   "source": [
    "print(\"Les nouvelles étiquettes NER ont été ajoutées au modèle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ffcbf-66ef-4cd5-8f5a-0e6e4444ac21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
