{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b558217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NER avec le modèle de base:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Tester le modèle de base\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest NER avec le modèle de base:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m test_ner_on_text(example_text, nlp_fr)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m### Chargement des données à partir d'un CSV et préparation pour l'entraînement\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Lecture des données annotées\u001b[39;00m\n\u001b[0;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../dataset/raw/initial_training_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     30\u001b[0m                  sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     31\u001b[0m                  encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     32\u001b[0m                  on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[152], line 16\u001b[0m, in \u001b[0;36mtest_ner_on_text\u001b[1;34m(text, model, labels, options)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_ner_on_text\u001b[39m(text, model, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     15\u001b[0m     doc \u001b[38;5;241m=\u001b[39m model(text)\n\u001b[1;32m---> 16\u001b[0m     spacy\u001b[38;5;241m.\u001b[39mdisplacy\u001b[38;5;241m.\u001b[39mrender(doc, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39moptions, jupyter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:56\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(docs, style, page, minify, jupyter, options, manual)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE096)\n\u001b[0;32m     55\u001b[0m renderer_func, converter \u001b[38;5;241m=\u001b[39m factories[style]\n\u001b[1;32m---> 56\u001b[0m renderer \u001b[38;5;241m=\u001b[39m renderer_func(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m     57\u001b[0m parsed \u001b[38;5;241m=\u001b[39m [converter(doc, options) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manual \u001b[38;5;28;01melse\u001b[39;00m docs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manual:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\render.py:524\u001b[0m, in \u001b[0;36mEntityRenderer.__init__\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE925\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(user_color)))\n\u001b[0;32m    523\u001b[0m     colors\u001b[38;5;241m.\u001b[39mupdate(user_color)\n\u001b[1;32m--> 524\u001b[0m colors\u001b[38;5;241m.\u001b[39mupdate(options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolors\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_color \u001b[38;5;241m=\u001b[39m DEFAULT_ENTITY_COLOR\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolors \u001b[38;5;241m=\u001b[39m {label\u001b[38;5;241m.\u001b[39mupper(): color \u001b[38;5;28;01mfor\u001b[39;00m label, color \u001b[38;5;129;01min\u001b[39;00m colors\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Chargement du modèle français pré-entraîné de spaCy\n",
    "nlp_fr = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Fonction de test NER sur un texte de démonstration\n",
    "def test_ner_on_text(text, model, labels=None, options=None):\n",
    "    doc = model(text)\n",
    "    spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)\n",
    "    \n",
    "# Exemple de texte pour tester le modèle avant et après l'entraînement\n",
    "example_text = '''Je voudrais aller de Toulouse à Bordeaux.\n",
    "Comment me rendre à Port-Boulet depuis la gare de Tours ?\n",
    "Je veux aller voir mon ami Albert à Tours en partant de Bordeaux.'''\n",
    "\n",
    "# Tester le modèle de base\n",
    "print(\"Test NER avec le modèle de base:\")\n",
    "test_ner_on_text(example_text, nlp_fr)\n",
    "\n",
    "### Chargement des données à partir d'un CSV et préparation pour l'entraînement\n",
    "# Lecture des données annotées\n",
    "df = pd.read_csv('../../dataset/raw/initial_training_data.csv', \n",
    "                 sep=',', \n",
    "                 encoding='utf-8', \n",
    "                 on_bad_lines='skip')\n",
    "\n",
    "# Aperçu rapide des données\n",
    "df.head()\n",
    "\n",
    "# Préparation des données pour spaCy\n",
    "def prepare_spacy_data(df, nlp_model, output_path):\n",
    "    db = DocBin()  # Conteneur pour les documents annotés\n",
    "\n",
    "    data = list(zip(df['text'], df['entities']))\n",
    "    shuffle(data)  # Mélange des données\n",
    "\n",
    "    def verify_entities(text, entities):\n",
    "        verified = []\n",
    "        for ent in entities:\n",
    "            start, end, label = ent['start'], ent['end'], ent['label']\n",
    "            entity_text = text[start:end]\n",
    "            # Vérification d'alignement des entités\n",
    "            if entity_text == text[start:end]:\n",
    "                verified.append(ent)\n",
    "        return verified\n",
    "\n",
    "    for text, entities in data:\n",
    "        entities = ast.literal_eval(entities)  # Conversion des entités du format string au format dict\n",
    "        verified_entities = verify_entities(text, entities)\n",
    "        if verified_entities:\n",
    "            doc = nlp_model.make_doc(text)\n",
    "            ents = []\n",
    "            for ent in verified_entities:\n",
    "                start, end, label = ent['start'], ent['end'], ent['label']\n",
    "                span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "                if span:\n",
    "                    ents.append(span)\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "\n",
    "    # Sauvegarde des données dans un format compatible avec spaCy\n",
    "    db.to_disk(output_path)\n",
    "\n",
    "# Préparation des données d'entraînement\n",
    "train_data_path = \"../../dataset/processed/processed_training_data.spacy\"\n",
    "prepare_spacy_data(df, nlp_fr, train_data_path)\n",
    "\n",
    "### Entrainement du modèle personnalisé\n",
    "# Création de fichier de configuration\n",
    "!python -m spacy init config ./config_itineraire.cfg --lang fr --pipeline ner --optimize efficiency --force\n",
    "\n",
    "# Lancement de l'entraînement\n",
    "!python -m spacy train ./config_itineraire.cfg --output ../../models/saved_models --paths.train {train_data_path} --paths.dev {train_data_path}\n",
    "\n",
    "### Évaluation et visualisation des résultats\n",
    "\n",
    "# Chargement du modèle entraîné\n",
    "nlp_custom = spacy.load(\"../../models/saved_models/model-best/\")\n",
    "\n",
    "# Définir les couleurs pour les entités\n",
    "colors = {\"DEPARTURE\": \"#ffe899\", \"DESTINATION\": \"#b1ff5e\", \"ESCALE\": \"#82b8ff\"}\n",
    "options = {\"ents\": [\"DEPARTURE\", \"DESTINATION\", \"ESCALE\"], \"colors\": colors}\n",
    "\n",
    "# Test sur le texte simple\n",
    "print(\"Test NER avec le modèle personnalisé:\")\n",
    "test_ner_on_text(example_text, nlp_custom, options=options)\n",
    "\n",
    "# Texte plus complexe pour tester davantage\n",
    "complex_text = '''Je souhaite me rendre à Lille en partant d'Aubervilliers pour assister à une conférence.\n",
    "Je compte me rendre à Bordeaux depuis Marseille pour rendre visite à ma soeur Paris.'''\n",
    "\n",
    "print(\"Test sur un texte plus complexe:\")\n",
    "test_ner_on_text(complex_text, nlp_custom, options=options)\n",
    "\n",
    "### Évaluation du modèle avec des graphiques\n",
    "\n",
    "# Exemple de texte avec des escales\n",
    "text_with_stops = '''Je souhaite me rendre à Lille en partant d'Aubervilliers pour assister à une conférence avec une escale à Nice.\n",
    "Je compte me rendre à Bordeaux depuis Marseille en m'arrêtant à Toulouse pour rendre visite à ma soeur Paris.'''\n",
    "\n",
    "# Fonction pour afficher des métriques de classification\n",
    "def evaluate_model(texts, labels, model):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for text, true_labels in zip(texts, labels):\n",
    "        doc = model(text)\n",
    "        pred_labels = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        preds.extend(pred_labels)\n",
    "        trues.extend(true_labels)\n",
    "    \n",
    "    return classification_report(trues, preds, output_dict=True), trues, preds\n",
    "\n",
    "# Générer des prédictions et afficher un rapport de classification\n",
    "texts = df['text'].tolist()\n",
    "entities = [ast.literal_eval(e) for e in df['entities'].tolist()]\n",
    "\n",
    "metrics, true_labels, pred_labels = evaluate_model(texts, entities, nlp_custom)\n",
    "\n",
    "# Afficher un rapport de classification\n",
    "print(\"Rapport de classification:\")\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "# Visualiser la matrice de confusion pour les prédictions\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    [label[2] for label in true_labels], \n",
    "    [label[2] for label in pred_labels], \n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "plt.title(\"Matrice de Confusion des Entités\")\n",
    "plt.show()\n",
    "\n",
    "# Visualisation des métriques avec des graphiques\n",
    "def plot_metrics(metrics):\n",
    "    df_metrics = pd.DataFrame(metrics).transpose()\n",
    "    df_metrics = df_metrics.drop(columns=[\"support\"])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df_metrics, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    plt.title(\"Rapport de Classification par Catégorie\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74334f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
