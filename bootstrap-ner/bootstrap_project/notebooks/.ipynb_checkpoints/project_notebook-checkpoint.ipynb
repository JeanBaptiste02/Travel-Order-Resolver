{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca78754-6947-45ac-a8bf-c019d722f5da",
   "metadata": {},
   "source": [
    "# Bootstrap T-AIA-901\n",
    "\n",
    "Ce notebook se concentre sur la reconnaissance des entités nommées (NER) dans le contexte des commandes de voyage.\n",
    "\n",
    "**But :** Identifier les entités comme les lieux de départ dans des phrases\n",
    "\n",
    "**Etapes :**\n",
    "- charger les données\n",
    "- prétraiter des données\n",
    "- utiliser des modèles pré-entrainés comme spaCy et Transformers pour la NER\n",
    "- entrainer les modèles avec les données qu'on a\n",
    "- évaluer et comparer les performances des modèles\n",
    "- visualiser les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7aeb3-9669-4dbb-9bb4-ad9d077d459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from spacy.training import Example\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbf119-a436-4eb0-aab9-026ccd10cbe3",
   "metadata": {},
   "source": [
    "## Chargement et Prétraitement des Données\n",
    "\n",
    "**Chargement du Dataset**\n",
    "\n",
    "Avant de commencer avec l'analyse des entités nommées, nous avons chargé les données depuis un fichier CSV.\n",
    "\n",
    "**Prétraitement des Données**\n",
    "\n",
    "Avant d'utiliser les données pour entrainer un modèle, il faut les prétraiter, c'est à dire : la normalisation du texte, la suppression des caractères non désirés et la mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dcd7b68c-eca7-4c01-864e-3036e1700e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement et prétraitement des données...\n",
      "Chargement du dataset...\n",
      "Affichage des premières lignes...\n",
      "  <PER>Dufan et Clémendot</PER>, <ACT>pharmaciens</ACT>, <LOC>r. de la ",
      "\n",
      "Chaussée-d&apos;Antin</LOC>, <CARDINAL>34</CARDINAL>. <TITRE>(Elig.)</TITRE> 449  \\\n",
      "0  <PER>Dufant (Victor)</PER>, <ACT>libraire</ACT...                                                                                                      \n",
      "1  <PER>Dufay</PER>, <ACT>essayeur du commerce</A...                                                                                                      \n",
      "2  <PER>Dulay</PER>, <ACT>chandronnier</ACT>, <LO...                                                                                                      \n",
      "3  <PER>Dufay (V.e)</PER>, <ACT>grenetière</ACT>,...                                                                                                      \n",
      "4  <PER>Dufay</PER>, <ACT>papetier</ACT>, <LOC>r....                                                                                                      \n",
      "\n",
      "    \"Bottin1_1820\"  \n",
      "0   \"Bottin1_1820\"  \n",
      "1   \"Bottin1_1820\"  \n",
      "2   \"Bottin1_1820\"  \n",
      "3   \"Bottin1_1820\"  \n",
      "4   \"Bottin1_1820\"  \n",
      "Prétraitement des données...\n",
      "Prétraitement terminé.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement et prétraitement des données...\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    return df\n",
    "\n",
    "print(\"Chargement du dataset...\")\n",
    "df = load_data('../data/bottins.csv')\n",
    "\n",
    "print(\"Affichage des premières lignes...\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Prétraitement des données...\")\n",
    "preprocessed_df = preprocess_data(df)\n",
    "print(\"Prétraitement terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650d766-c7cd-46e0-84b4-07fe40db598f",
   "metadata": {},
   "source": [
    "## Analyse des Entités Nommées avec spaCy\n",
    "\n",
    "**Chargement du Modèle spaCy**\n",
    "\n",
    "spaCy est une librairie connue pour NLP. On utilise un modèle pré-entrainé pour reconnaitre/identifier les entités nommées (NER) dans un texte.\n",
    "\n",
    "**Traitement du Texte avec spaCy**\n",
    "\n",
    "Une fois que le chargé est chargé, on l'applique au texte pour identifier les entités nommées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8224d14-cec0-4c39-8dce-690a7620b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse des entités nommées avec spaCy...\n",
      "je m'appelle John, je serai votre encadrant à Epitech. je viens de Paris pour aller à Marseille\n",
      "Chargement du modèle spaCy...\n",
      "Traitement du texte avec spaCy...\n",
      "Entités reconnues :\n",
      "Texte : John, Label : PER\n",
      "Texte : Epitech, Label : ORG\n",
      "Texte : Paris, Label : LOC\n",
      "Texte : Marseille, Label : LOC\n",
      "Entités reconnues par spaCy :\n",
      "[('John', 'PER'), ('Epitech', 'ORG'), ('Paris', 'LOC'), ('Marseille', 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyse des entités nommées avec spaCy...\")\n",
    "\n",
    "def spacy_inference(text):\n",
    "    print(\"Chargement du modèle spaCy...\")\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    print(\"Traitement du texte avec spaCy...\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    print(\"Entités reconnues :\")\n",
    "    for entity in entities:\n",
    "        print(f\"Texte : {entity[0]}, Label : {entity[1]}\")\n",
    "    \n",
    "    return entities\n",
    "\n",
    "text = \"je m'appelle John, je serai votre encadrant à Epitech. je viens de Paris pour aller à Marseille\"\n",
    "print(text)\n",
    "entities = spacy_inference(text)\n",
    "print(\"Entités reconnues par spaCy :\")\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8f313-43c6-4676-9e8d-7986265f8bd3",
   "metadata": {},
   "source": [
    "## Analyse des Entités Nommées avec Transformers\n",
    "\n",
    "**Initialisation du Pipeline NER avec Transformers**\n",
    "\n",
    "Transformers est une autre librairie qui offre des modèles pré-entrainés basé sur des archietcture modernes comme BERT.\n",
    "\n",
    "**Traitement du Texte avec Transformers**\n",
    "\n",
    "Après initialisation, on utilise le modèle Transformers pour identifier les entités nommées dans le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18db921e-ba27-4b16-9039-9bc43e701abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des entités nommées avec Transformers...\n",
      "Initialisation du pipeline NER avec Transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n",
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du texte avec Transformers...\n",
      "Entités reconnues :\n",
      "Texte : John, Label : I-PER, Score : 0.9989\n",
      "Texte : E, Label : I-ORG, Score : 0.9986\n",
      "Texte : ##pit, Label : I-ORG, Score : 0.9522\n",
      "Texte : ##ech, Label : I-ORG, Score : 0.9806\n",
      "Texte : Paris, Label : I-LOC, Score : 0.9984\n",
      "Texte : Lyon, Label : I-LOC, Score : 0.9938\n",
      "Entités reconnues par Transformers :\n",
      "{'entity': 'I-PER', 'score': 0.9989214, 'index': 4, 'word': 'John', 'start': 11, 'end': 15}\n",
      "{'entity': 'I-ORG', 'score': 0.9986092, 'index': 11, 'word': 'E', 'start': 35, 'end': 36}\n",
      "{'entity': 'I-ORG', 'score': 0.95216924, 'index': 12, 'word': '##pit', 'start': 36, 'end': 39}\n",
      "{'entity': 'I-ORG', 'score': 0.98063767, 'index': 13, 'word': '##ech', 'start': 39, 'end': 42}\n",
      "{'entity': 'I-LOC', 'score': 0.99844754, 'index': 18, 'word': 'Paris', 'start': 58, 'end': 63}\n",
      "{'entity': 'I-LOC', 'score': 0.99379987, 'index': 20, 'word': 'Lyon', 'start': 67, 'end': 71}\n"
     ]
    }
   ],
   "source": [
    "print(\"Extraction des entités nommées avec Transformers...\")\n",
    "\n",
    "def transformers_inference(text, model_name=\"dbmdz/bert-large-cased-finetuned-conll03-english\"):\n",
    "    print(\"Initialisation du pipeline NER avec Transformers...\")\n",
    "    ner_pipeline = pipeline(\"ner\", model=model_name)\n",
    "    \n",
    "    print(\"Traitement du texte avec Transformers...\")\n",
    "    results = ner_pipeline(text)\n",
    "    \n",
    "    print(\"Entités reconnues :\")\n",
    "    for result in results:\n",
    "        print(f\"Texte : {result['word']}, Label : {result['entity']}, Score : {result['score']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "text = \"My name is John, i am a teacher at Epitech. I travel from Paris to Lyon everyday.\"\n",
    "results = transformers_inference(text)\n",
    "print(\"Entités reconnues par Transformers :\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eff7f0-6f92-4c39-bba6-38b4429220d3",
   "metadata": {},
   "source": [
    "## Entraînement du Modèle NER avec spaCy\n",
    "\n",
    "**Entraînement du Modèle**\n",
    "\n",
    "C'est l'étape où le modèle apprend.\n",
    "L'entrainement du modèle NER implique de l'ajuster sur des données spécifiques pour améliorer sa précision. Le modèle\n",
    "Le modèle est ajusté sur plusieurs epochs pour apprendre à identifier les entités avec précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "53465043-89f2-4e2e-818a-2c6ea32fbb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle NER avec spaCy...\n",
      "Epoch 0 en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Je veux aller de Paris à Mumbai\" with entities \"[(18, 23, 'DEP'), (27, 33, 'ARR')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.3276451889504699}\n",
      "Epoch 1 en cours...\n",
      "Epoch 1 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.02694186654760955}\n",
      "Epoch 2 en cours...\n",
      "Epoch 2 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.003725719503354874}\n",
      "Epoch 3 en cours...\n",
      "Epoch 3 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.011250158434187085}\n",
      "Epoch 4 en cours...\n",
      "Epoch 4 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.004061764701084792}\n",
      "Epoch 5 en cours...\n",
      "Epoch 5 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.06034897325128763}\n",
      "Epoch 6 en cours...\n",
      "Epoch 6 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.000513426049533347}\n",
      "Epoch 7 en cours...\n",
      "Epoch 7 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.0022167037375702137}\n",
      "Epoch 8 en cours...\n",
      "Epoch 8 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 1.0668359179270663e-05}\n",
      "Epoch 9 en cours...\n",
      "Epoch 9 terminée. Pertes : {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 0.0002170571511150854}\n",
      "Entraînement terminé.\n"
     ]
    }
   ],
   "source": [
    "print(\"Entraînement du modèle NER avec spaCy...\")\n",
    "\n",
    "def train_model(nlp, TRAIN_DATA):\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # Ajout des nouvelles étiquettes\n",
    "    ner.add_label(\"DEP\")\n",
    "    ner.add_label(\"ARR\")\n",
    "    \n",
    "    optimizer = nlp.resume_training()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        losses = {}\n",
    "        print(f\"Epoch {epoch} en cours...\")\n",
    "        \n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)            \n",
    "            nlp.update([example], drop=0.5, losses=losses)\n",
    "        \n",
    "        print(f\"Epoch {epoch} terminée. Pertes : {losses}\")\n",
    "\n",
    "    print(\"Entraînement terminé.\")\n",
    "    return nlp\n",
    "\n",
    "TRAIN_DATA = [\n",
    "    (\"Je veux aller de Paris à Mumbai\", {\"entities\": [(18, 23, \"DEP\"), (27, 33, \"ARR\")]}),\n",
    "]\n",
    "\n",
    "trained_nlp = train_model(spacy.load(\"fr_core_news_lg\"), TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a0f4cc7f-97fb-43a0-9167-390fb6d9c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données pour l'entraînement RNN/LSTM...\n",
      "Données préparées pour RNN/LSTM.\n",
      "Construction du modèle RNN/LSTM...\n",
      "Modèle compilé.\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.2857 - loss: 0.6994\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7143 - loss: 0.6874\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.8571 - loss: 0.6717\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8571 - loss: 0.6652\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8571 - loss: 0.6516\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8571 - loss: 0.6419\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8571 - loss: 0.6276\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8571 - loss: 0.6121\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 0.6004\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 0.5894\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8571 - loss: 0.5768\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8571 - loss: 0.5559\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8571 - loss: 0.5499\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8571 - loss: 0.5375\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8571 - loss: 0.4937\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8571 - loss: 0.4931\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8571 - loss: 0.4962\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8571 - loss: 0.4917\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8571 - loss: 0.4770\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8571 - loss: 0.4328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2e51b709550>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_rnn_data(df):\n",
    "    print(\"Préparation des données pour l'entraînement RNN/LSTM...\")\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['text'])\n",
    "    sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "    X = pad_sequences(sequences, padding='post')\n",
    "    \n",
    "    max_len = X.shape[1]\n",
    "    y = np.array(df['label'][0])\n",
    "    \n",
    "    y = np.pad(y, (0, max_len - len(y)), 'constant') if len(y) < max_len else y[:max_len]\n",
    "    y = np.reshape(y, (1, max_len))\n",
    "    y = to_categorical(y, num_classes=len(set(y.flatten())))\n",
    "    \n",
    "    print(\"Données préparées pour RNN/LSTM.\")\n",
    "    return X, y, tokenizer\n",
    "\n",
    "df_rnn = pd.DataFrame({\n",
    "    'text': [\"Je veux aller de Paris à Monaco\"],\n",
    "    'label': [[0, 0, 0, 1, 0, 0, 0, 1]]  # format one-hot pour simplification\n",
    "})\n",
    "\n",
    "X, y, tokenizer = prepare_rnn_data(df_rnn)\n",
    "\n",
    "def build_rnn_model(vocab_size, num_classes):\n",
    "    print(\"Construction du modèle RNN/LSTM...\")\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Modèle compilé.\")\n",
    "    return model\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "num_classes = y.shape[2]\n",
    "\n",
    "model_rnn = build_rnn_model(vocab_size, num_classes)\n",
    "model_rnn.fit(X, y, epochs=20, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58932916-9311-4539-825a-6c335ad62ba6",
   "metadata": {},
   "source": [
    "## Évaluation des Modèles\n",
    "\n",
    "**Évaluation des Métriques spaCy**\n",
    "\n",
    "On évalue les performances du modèle spaCy sur des textes de test pour voir comment il se comporte en termes de précision.\n",
    "\n",
    "**Évaluation des Métriques RNN**\n",
    "\n",
    "De même, on évalue le modèle RNN (Modèles de réseaux de neurones utilisés pour traiter les séquences de texte) sur le même texte. \n",
    "\n",
    "_Métriques : Mesures de performance du modèle telles que la précision, le rappel, et le score F1, qui indiquent combien le modèle est précis et complet dans ses prédictions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7d2658b-f95f-44a5-874f-d1e4558a1e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating spacy metrics\n",
      "Processing text: Je veux aller de Paris à Marseille\n",
      "Annotations: {'entities': [(18, 23, 'DEP'), (27, 35, 'ARR')]}\n",
      "True labels: ['DEP', 'ARR']\n",
      "Predicted labels: []\n",
      "No true or predicted labels found.\n",
      "None\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Evaluating rnn metrics\n",
      "Processing sentence: Je veux aller de Paris à Marseille\n",
      "Annotations: {'entities': [(18, 23, 'DEP'), (27, 35, 'ARR')]}\n",
      "Tokens: [[1 2 3 4 5 6]]\n",
      "Avertissement : Indices 18, 23 hors limites pour la phrase : Je veux aller de Paris à Marseille\n",
      "Avertissement : Indices 27, 35 hors limites pour la phrase : Je veux aller de Paris à Marseille\n",
      "True labels: ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predictions: ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "Generating classification report...\n",
      "{'O': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_spacy_model(nlp, test_data):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for text, annotations in test_data:\n",
    "        print(f\"Processing text: {text}\")\n",
    "        print(f\"Annotations: {annotations}\")\n",
    "\n",
    "        doc = nlp(text)\n",
    "        true_labels = [ent[2] for ent in annotations[\"entities\"] if ent[2] in [\"DEP\", \"ARR\"]]\n",
    "        pred_labels = [ent.label_ for ent in doc.ents if ent.label_ in [\"DEP\", \"ARR\"]]\n",
    "\n",
    "        print(f\"True labels: {true_labels}\")\n",
    "        print(f\"Predicted labels: {pred_labels}\")\n",
    "\n",
    "        if true_labels and pred_labels:\n",
    "            y_true.extend(true_labels)\n",
    "            y_pred.extend(pred_labels)\n",
    "\n",
    "    if not y_true or not y_pred:\n",
    "        print(\"No true or predicted labels found.\")\n",
    "        return None\n",
    "\n",
    "    print(\"Generating classification report...\")\n",
    "    return classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "def evaluate_rnn_model(model, tokenizer, test_data):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    label_mapping = {0: 'O', 1: 'DEP', 2: 'ARR'} \n",
    "\n",
    "    for sentence, annotations in test_data:\n",
    "        print(f\"Processing sentence: {sentence}\")\n",
    "        print(f\"Annotations: {annotations}\")\n",
    "\n",
    "        tokens = tokenizer.texts_to_sequences([sentence])[0]\n",
    "        tokens = np.array(tokens).reshape(1, -1) \n",
    "\n",
    "        print(f\"Tokens: {tokens}\")\n",
    "\n",
    "        true_labels = ['O'] * len(tokens[0])\n",
    "\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            if start < len(true_labels) and end <= len(true_labels):\n",
    "                true_labels[start] = label\n",
    "            else:\n",
    "                print(f\"Avertissement : Indices {start}, {end} hors limites pour la phrase : {sentence}\")\n",
    "\n",
    "        print(f\"True labels: {true_labels}\")\n",
    "\n",
    "        pred_labels = model.predict(tokens)\n",
    "        pred_labels = np.argmax(pred_labels[0], axis=-1)\n",
    "        pred_labels = [label_mapping[pred] for pred in pred_labels]  \n",
    "\n",
    "        print(f\"Predictions: {pred_labels}\")\n",
    "\n",
    "        if len(pred_labels) != len(true_labels):\n",
    "            print(f\"Erreur : Longueur des prédictions ({len(pred_labels)}) différente des étiquettes vraies ({len(true_labels)}) pour la phrase : {sentence}\")\n",
    "            continue \n",
    "            \n",
    "        y_true.extend(true_labels)\n",
    "        y_pred.extend(pred_labels)\n",
    "\n",
    "    print(\"Generating classification report...\")\n",
    "    return classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "test_data = [\n",
    "    (\"Je veux aller de Paris à Marseille\", {\"entities\": [(18, 23, \"DEP\"), (27, 35, \"ARR\")]}),\n",
    "]\n",
    "\n",
    "print(\"Evaluating spacy metrics\")\n",
    "spacy_metrics = evaluate_spacy_model(trained_nlp, test_data)\n",
    "print(spacy_metrics)\n",
    "\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "\n",
    "print(\"Evaluating rnn metrics\")\n",
    "rnn_metrics = evaluate_rnn_model(model_rnn, tokenizer, test_data)\n",
    "print(rnn_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee6753-908d-4b6b-8170-f0d055224ae6",
   "metadata": {},
   "source": [
    "## Comparaison des Modèles spaCy et RNN\n",
    "\n",
    "**spaCy vs Transformers**\n",
    "\n",
    "spaCy : Offre des résultats rapides et précis avec des modèles pré-entraînés. Il est souvent utilisé pour des tâches pratiques en production.\n",
    "Transformers : Fournit des modèles basés sur des architectures modernes comme BERT, qui peuvent offrir une meilleure compréhension contextuelle mais nécessitent plus de ressources.\n",
    "\n",
    "**RNN**\n",
    "\n",
    "RNN : Peut avoir des difficultés avec les longues séquences et les indices hors limites, ce qui peut entraîner des performances inférieures. Les modèles basés sur Transformers sont généralement préférés pour les tâches NER modernes.\n",
    "\n",
    "\n",
    "**En conclusion**, spaCy et Transformers sont généralement plus performants pour les tâches NER modernes par rapport aux RNN traditionnels. spaCy est excellent pour des applications rapides et efficaces, tandis que Transformers, avec des architectures avancées, offre une compréhension contextuelle plus profonde mais à un coût plus élevé en ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4fdb73ac-cf24-41d9-bc05-35037dab4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text: Je veux aller de Paris à Marseille\n",
      "Annotations: {'entities': [(18, 23, 'DEP'), (27, 35, 'ARR')]}\n",
      "True labels: ['DEP', 'ARR']\n",
      "Predicted labels: []\n",
      "No true or predicted labels found.\n",
      "Processing sentence: Je veux aller de Paris à Marseille\n",
      "Annotations: {'entities': [(18, 23, 'DEP'), (27, 35, 'ARR')]}\n",
      "Tokens: [[1 2 3 4 5 6]]\n",
      "Avertissement : Indices 18, 23 hors limites pour la phrase : Je veux aller de Paris à Marseille\n",
      "Avertissement : Indices 27, 35 hors limites pour la phrase : Je veux aller de Paris à Marseille\n",
      "True labels: ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Predictions: ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "Generating classification report...\n",
      "Les métriques ne sont pas disponibles. Assurez-vous que les fonctions d'évaluation ont fonctionné correctement.\n"
     ]
    }
   ],
   "source": [
    "def plot_comparison(spacy_metrics, rnn_metrics):\n",
    "    # Vérifiez que les résultats ne sont pas None\n",
    "    if spacy_metrics is None or rnn_metrics is None:\n",
    "        print(\"Les métriques ne sont pas disponibles. Assurez-vous que les fonctions d'évaluation ont fonctionné correctement.\")\n",
    "        return\n",
    "\n",
    "    # Vérifiez que les clés 'DEP' existent dans les métriques\n",
    "    if 'DEP' not in spacy_metrics or 'DEP' not in rnn_metrics:\n",
    "        print(\"Les clés 'DEP' sont manquantes dans les métriques.\")\n",
    "        return\n",
    "\n",
    "    metrics = [\"precision\", \"recall\", \"f1-score\"]\n",
    "\n",
    "    spacy_scores = [spacy_metrics[\"DEP\"].get(\"precision\", 0), spacy_metrics[\"DEP\"].get(\"recall\", 0), spacy_metrics[\"DEP\"].get(\"f1-score\", 0)]\n",
    "    rnn_scores = [rnn_metrics[\"DEP\"].get(\"precision\", 0), rnn_metrics[\"DEP\"].get(\"recall\", 0), rnn_metrics[\"DEP\"].get(\"f1-score\", 0)]\n",
    "\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars1 = ax.bar(x - width/2, spacy_scores, width, label='spaCy')\n",
    "    bars2 = ax.bar(x + width/2, rnn_scores, width, label='RNN/LSTM')\n",
    "\n",
    "    ax.set_xlabel('Métriques')\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Comparaison des Modèles NER')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "spacy_metrics = evaluate_spacy_model(trained_nlp, test_data) \n",
    "rnn_metrics = evaluate_rnn_model(model_rnn, tokenizer, test_data) \n",
    "\n",
    "plot_comparison(spacy_metrics, rnn_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
