{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6769e4b",
   "metadata": {},
   "source": [
    "# Description du Notebook\n",
    "\n",
    "Ce notebook permet d'entraîner un modèle de NER en français avec spaC en se basant les infos de voyage. \n",
    "\n",
    "Les étapes incluent : \n",
    "- l'importation, le nettoyage et la préparation des données annotées,\n",
    "- l'entraînement du modèle. \n",
    "\n",
    "Ensuite, on fait un comparaison de performances entre le modèle personnalisé et le modèle spaCy préentraîné, avec des visualisations pour évaluer la diversité et le nombre d'entités détectées par chaque modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603bc3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle spaCy sm...\n",
      "Modèle spaCy sm chargé avec succès\n",
      "Chargement du modèle spaCy md...\n",
      "Modèle spaCy md chargé avec succès\n",
      "Chargement du modèle spaCy lg...\n",
      "Modèle spaCy lg chargé avec succès\n",
      "Chargement du dataset à partir de C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/raw/generated_dataset/text.csv...\n",
      "Colonnes du dataset: Index(['text', 'CORRECT', 'NOT_FRENCH', 'NOT_TRIP', 'UNKNOWN'], dtype='object')\n",
      "Chargement du dataset à partir de C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/raw/generated_dataset/token.csv...\n",
      "Colonnes du dataset: Index(['text', 'tokens', 'ner_tags', 'spacy_ner_tags'], dtype='object')\n",
      "                                                text  CORRECT  NOT_FRENCH  \\\n",
      "0  The journey from the central square of carnoul...        0           1   \n",
      "1  J'aimerais me rendre de l'aéroport de vendôme-...        1           0   \n",
      "2  De l'hopital de ste-croix mines-sq-de-g à bert...        1           0   \n",
      "3        I'd like about three kilograms of potatoes.        0           1   \n",
      "4                          pxwj r b dmkavmyxb  k qws        0           0   \n",
      "\n",
      "   NOT_TRIP  UNKNOWN  \n",
      "0         0        0  \n",
      "1         0        0  \n",
      "2         0        0  \n",
      "3         1        0  \n",
      "4         0        1  \n",
      "                                                text  tokens  ner_tags  \\\n",
      "0  Aller de CHAUMONT à CAVAILLON.,\"['Aller', 'de'...     NaN       NaN   \n",
      "1  Comment aller à LE TAMPON depuis MATOURY ?,\"['...     NaN       NaN   \n",
      "2  Comment atteindre CALAIS depuis LE GOSIER ?,\"[...     NaN       NaN   \n",
      "3  Comment atteindre BELFORT en partant de REZÉ l...     NaN       NaN   \n",
      "4  Comment atteindre DRANCY à partir de GRASSE ?,...     NaN       NaN   \n",
      "\n",
      "   spacy_ner_tags  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "La colonne 'spacy_ner_tags' n'existe pas dans le DataFrame.\n",
      "La colonne 'spacy_ner_tags' est présente.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m     doc_bin\u001b[38;5;241m.\u001b[39mto_disk(output_path)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Sauvegarder les données converties pour chaque dataset\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m save_to_spacy_format(df_text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_text.spacy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m save_to_spacy_format(df_token, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_token.spacy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLes données ont été sauvegardées au format spaCy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 86\u001b[0m, in \u001b[0;36msave_to_spacy_format\u001b[1;34m(df, output_path)\u001b[0m\n\u001b[0;32m     84\u001b[0m doc_bin \u001b[38;5;241m=\u001b[39m DocBin()  \u001b[38;5;66;03m# Utilisé pour sauvegarder les données spaCy\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, annotations \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspacy_ner_tags\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m---> 86\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp_models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msm\u001b[39m\u001b[38;5;124m\"\u001b[39m](text)  \u001b[38;5;66;03m# Utilisation du modèle de base pour tokeniser\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     ents \u001b[38;5;241m=\u001b[39m verify_entity_alignment(doc\u001b[38;5;241m.\u001b[39mtext, annotations)\n\u001b[0;32m     88\u001b[0m     spans \u001b[38;5;241m=\u001b[39m create_entity_spans(doc, ents)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[0;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[1;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[0;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[1;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgemm(X, W, trans2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[0;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import pandas as pd\n",
    "import ast\n",
    "from random import shuffle\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Liste des modèles spaCy à tester\n",
    "models = {\n",
    "    \"sm\": \"fr_core_news_sm\",\n",
    "    \"md\": \"fr_core_news_md\",\n",
    "    \"lg\": \"fr_core_news_lg\"\n",
    "}\n",
    "\n",
    "# Chargement des modèles spaCy\n",
    "nlp_models = {}\n",
    "for model_key, model_name in models.items():\n",
    "    print(f\"Chargement du modèle spaCy {model_key}...\")\n",
    "    nlp_models[model_key] = spacy.load(model_name)\n",
    "    print(f\"Modèle spaCy {model_key} chargé avec succès\")\n",
    "\n",
    "# Fonction de nettoyage du texte\n",
    "def clean_text(text):\n",
    "    return text.replace('\\r', '').strip()\n",
    "\n",
    "# Fonction pour vérifier l'alignement des entités\n",
    "def verify_entity_alignment(text, entities):\n",
    "    verified_entities = []\n",
    "    for ent in entities:\n",
    "        start, end, label = ent['start'], ent['end'], ent['label']\n",
    "        if text[start:end] == text[start:end]:  # Vérification basique d'alignement\n",
    "            verified_entities.append(ent)\n",
    "        else:\n",
    "            print(f\"Skipping entity: {text[start:end]} in text: {text}\")\n",
    "    return verified_entities\n",
    "\n",
    "# Fonction pour préparer les données au format spaCy\n",
    "def prepare_data_for_spacy_from_csv(df):\n",
    "    # Vérification de l'existence de la colonne 'spacy_ner_tags'\n",
    "    if 'spacy_ner_tags' not in df.columns:\n",
    "        print(\"La colonne 'spacy_ner_tags' n'existe pas dans le DataFrame.\")\n",
    "        # Créer une liste vide de la même longueur que le DataFrame\n",
    "        df['spacy_ner_tags'] = [[] for _ in range(len(df))]  # Liste vide pour chaque ligne\n",
    "    else:\n",
    "        print(\"La colonne 'spacy_ner_tags' est présente.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "def load_dataset(file_path):\n",
    "    print(f\"Chargement du dataset à partir de {file_path}...\")\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='utf-8', on_bad_lines='skip')\n",
    "    print(\"Colonnes du dataset:\", df.columns)\n",
    "    return df\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "df_text = load_dataset(\"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/raw/generated_dataset/text.csv\")\n",
    "df_token = load_dataset(\"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/raw/generated_dataset/token.csv\")\n",
    "\n",
    "# Vérification et nettoyage des colonnes de texte\n",
    "if 'text' in df_text.columns:\n",
    "    df_text['text'] = df_text['text'].apply(clean_text)\n",
    "else:\n",
    "    print(\"La colonne 'text' n'existe pas dans df_text\")\n",
    "\n",
    "if 'text' in df_token.columns:\n",
    "    df_token['text'] = df_token['text'].apply(clean_text)\n",
    "else:\n",
    "    print(\"La colonne 'text' n'existe pas dans df_token\")\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "print(df_text.head())\n",
    "print(df_token.head())\n",
    "\n",
    "# Préparer les données pour spaCy\n",
    "df_text = prepare_data_for_spacy_from_csv(df_text)\n",
    "df_token = prepare_data_for_spacy_from_csv(df_token)\n",
    "\n",
    "# Sauvegarder les données converties au format spaCy\n",
    "def save_to_spacy_format(df, output_path):\n",
    "    doc_bin = DocBin()  # Utilisé pour sauvegarder les données spaCy\n",
    "    for text, annotations in zip(df['text'], df['spacy_ner_tags']):\n",
    "        doc = nlp_models[\"sm\"](text)  # Utilisation du modèle de base pour tokeniser\n",
    "        ents = verify_entity_alignment(doc.text, annotations)\n",
    "        spans = create_entity_spans(doc, ents)\n",
    "        doc.ents = spans\n",
    "        doc_bin.add(doc)\n",
    "    doc_bin.to_disk(output_path)\n",
    "\n",
    "# Sauvegarder les données converties pour chaque dataset\n",
    "save_to_spacy_format(df_text, \"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_text.spacy\")\n",
    "save_to_spacy_format(df_token, \"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_token.spacy\")\n",
    "print(\"Les données ont été sauvegardées au format spaCy.\")\n",
    "\n",
    "# Fonction pour créer les spans d'entités dans spaCy\n",
    "def create_entity_spans(doc, verified_entities):\n",
    "    ents = []\n",
    "    for ent in verified_entities:\n",
    "        start, end, label = ent['start'], ent['end'], ent['label']\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span:\n",
    "            ents.append(span)\n",
    "    return ents\n",
    "\n",
    "# Fonction pour entraîner le modèle\n",
    "def train_model(config_path, output_path, training_data_path):\n",
    "    print(\"Génération de la configuration...\")\n",
    "    subprocess.run(f\"python -m spacy init config {config_path} --lang fr --pipeline ner --optimize efficiency --force\", shell=True)\n",
    "    print(\"Configuration générée.\")\n",
    "\n",
    "    print(\"Début de l'entraînement du modèle...\")\n",
    "    process = subprocess.Popen(f\"python -m spacy train {config_path} --output {output_path} --paths.train {training_data_path} --paths.dev {training_data_path}\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    with tqdm(total=100, desc=\"Entraînement du modèle\") as pbar:\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == b\"\" and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.decode().strip()) \n",
    "            pbar.update(1)\n",
    "            time.sleep(1)\n",
    "\n",
    "# Entraînement des modèles pour chaque dataset (text et token)\n",
    "datasets = [\n",
    "    (\"text\", \"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_text.spacy\"),\n",
    "    (\"token\", \"C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/dataset/processed/processed_training_data_token.spacy\")\n",
    "]\n",
    "\n",
    "for dataset_name, dataset_path in datasets:\n",
    "    for model_key in models.keys():\n",
    "        print(f\"Entraînement pour le modèle {model_key} avec le dataset {dataset_name}...\")\n",
    "        train_model('./configuration.cfg', f'C:/Users/vikne/Documents/Master 2/Semestre 9/Intelligence artificielle/Travel-Order-Resolver/ai/nlp/models/spacy/{model_key}', dataset_path)\n",
    "        print(f\"Entraînement du modèle {model_key} terminé pour le dataset {dataset_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
